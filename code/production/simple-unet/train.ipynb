{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.optimizers import AdamW\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from unet_model import UNet_v2\n",
    "from loss import focal_tversky, tversky, accuracy, dice_coef\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# ============================\n",
    "# Argument Parsing\n",
    "# ============================\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train_dir', type=str, required=True, help='Path to training data directory')\n",
    "parser.add_argument('--val_dir', type=str, required=True, help='Path to validation data directory')\n",
    "parser.add_argument('--epochs', type=int, default=20)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--output', type=str, default='unet_model.keras')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# ============================\n",
    "# Dataset Loader\n",
    "# ============================\n",
    "def get_image_mask_paths(data_dir):\n",
    "    all_files = os.listdir(data_dir)\n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    for f in all_files:\n",
    "        if '_annotation_and_boundary' not in f and f.endswith('.png'):\n",
    "            mask = f.replace('.png', '_annotation_and_boundary.png')\n",
    "            if mask in all_files:\n",
    "                image_paths.append(os.path.join(data_dir, f))\n",
    "                mask_paths.append(os.path.join(data_dir, mask))\n",
    "    return image_paths, mask_paths\n",
    "\n",
    "def load_image_mask(image_path, mask_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = image.astype(np.float32)\n",
    "    image = (image - np.mean(image)) / (np.std(image) + 1e-8)  # z-score normalization\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = (mask > 0).astype(np.float32)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def random_augment(image, mask):\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = np.fliplr(image)\n",
    "        mask = np.fliplr(mask)\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = np.flipud(image)\n",
    "        mask = np.flipud(mask)\n",
    "\n",
    "    if np.random.rand() > 0.7:\n",
    "        max_shift = 20  # pixel shift\n",
    "        dx = np.random.randint(-max_shift, max_shift)\n",
    "        dy = np.random.randint(-max_shift, max_shift)\n",
    "        h, w = image.shape[:2]\n",
    "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "        mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    if np.random.rand() > 0.7:\n",
    "        angle = np.random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1)\n",
    "        image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "        mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    if np.random.rand() > 0.7:\n",
    "        factor = np.random.uniform(0.8, 1.2)\n",
    "        image = np.clip(image * factor, 0, 1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "class ImageMaskGenerator:\n",
    "    def __init__(self, image_paths, mask_paths, batch_size, augment=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            image, mask = load_image_mask(self.image_paths[i], self.mask_paths[i])\n",
    "            if self.augment:\n",
    "                image, mask = random_augment(image, mask)\n",
    "            batch_images.append(image)\n",
    "            batch_masks.append(mask)\n",
    "\n",
    "        return np.array(batch_images), np.array(batch_masks)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "# ============================\n",
    "# Training Setup\n",
    "# ============================\n",
    "train_image_paths, train_mask_paths = get_image_mask_paths(args.train_dir)\n",
    "val_image_paths, val_mask_paths = get_image_mask_paths(args.val_dir)\n",
    "\n",
    "train_gen = ImageMaskGenerator(train_image_paths, train_mask_paths, args.batch_size, augment=True)\n",
    "val_gen = ImageMaskGenerator(val_image_paths, val_mask_paths, args.batch_size, augment=False)\n",
    "\n",
    "# ============================\n",
    "# Model Build\n",
    "# ============================\n",
    "input_shape = (512, 512, 1)\n",
    "model = UNet_v2(input_shape)\n",
    "\n",
    "model.compile(optimizer=AdamW(learning_rate=1e-3, weight_decay=1e-5), loss=tversky, metrics=[dice_coef, accuracy])\n",
    "\n",
    "# ============================\n",
    "# Training\n",
    "# ============================\n",
    "checkpoint = ModelCheckpoint(args.output, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=args.epochs,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "print(f'Model saved to {args.output}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsfc311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
